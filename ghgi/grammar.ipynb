{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INPUT = [\n",
    "'4 large (8 to 9 ounces each) chicken breast halves, each cut in half crosswise to make 8 pieces total',\n",
    "'unsalted, softened butter, softened: 9 tablespoons (4.5 ounces or 128 grams)',\n",
    "'1¼ cup/80 grams plus 2 teaspoons/5 grams mild honey',\n",
    "'1/2 pound fresh tuna, grilled or 6 1/2- to 7-ounce can albacore tuna, packed in water',\n",
    "'1 salmon or other firm fish, about 2 pounds, gutted and scaled, with the head left on',\n",
    "'4 whole fish, like sea bass or black bass, 1 to 1 1/2 pounds each', # PROBLEMATIC b/c we lose the whole \"like\" phrase\n",
    "'4 whole fish,, like sea bass or black bass, 1 to 1.5 pounds each', # PROBLEMATIC b/c we lose the whole \"like\" phrase\n",
    "'2 cans (10 ounces each) of condensed cream of celery or cream of mushroom soup',\n",
    "'2 cans (10 ounces/280 grams each) of condensed cream of celery or cream of mushroom soup',\n",
    "'1 six-to-eight-pound, cleaned, whole salmon, preferably with head left on (see note)',\n",
    "'Two 5-ounce (140g) cans tuna in olive oil, drained (or 10 ounces/280g shredded roast chicken meat)',\n",
    "'1 (5-ounce) can tuna packed in olive oil, preferably Italian (see note)',\n",
    "'1 pound boneless, skinless chicken breast, cut across the grain in 1/4-inch thick slices',\n",
    "'grape or cherry tomatoes',\n",
    "'grape or cherry tomato',\n",
    "'ripe or green cherry tomato',\n",
    "'2 4-pound Atlantic salmon (2 1/4 inches at thickest point), scaled and cleaned, gills removed, head and tail on, interior cavity well washed',\n",
    "'2 cotechini (Italian garlic sausages), about 1 pound each (available at Italian butcher shops)',\n",
    "'1¼ cup/80 grams mild honey',\n",
    "'1 (5- or 6-ounce) can or jar tuna, drained and flaked, or 1 (13-ounce) can chickpeas or white beans, drained',\n",
    "'2 (6-ounce) cans Italian tuna in water or oil, drained',\n",
    "'1 (4-ounce) can smoked mussels',\n",
    "'1¼ cup (approx. 80 grams) mild honey',\n",
    "'350g (approx. 1 1/2 cups) mild honey',\n",
    "'4 boneless, skinless chicken breasts (6 to 8 ounces each)',\n",
    "'2 medium-size tomatoes, each seeded and cut into 6 pieces',\n",
    "'handful peanuts',\n",
    "'chopped parsley',\n",
    "'1-1/2 tablespoons Dijon mustard',\n",
    "'5-to-6-pound, cleaned, whole salmon, preferably with head left on (see note)',\n",
    "'1 5-to-6-pound, cleaned, whole salmon, preferably with head left on (see note)',\n",
    "'1 five- to six-pound, cleaned, whole salmon, preferably with head left on (see note)',\n",
    "'1 (1 1/2-pound) salmon fillet, skin-on or skinless',\n",
    "'6 cup',\n",
    "'6 cups',\n",
    "'6 cups <a href=\"https://cooking.nytimes.com/recipes/1021916-vegan-bolognese\">vegan Bolognese</a>',\n",
    "'1 cup flour',\n",
    "'1 c flour',\n",
    "'1.5c flour',\n",
    "'1 1/2c flour',\n",
    "'For the filling:  ',\n",
    "'1 packed cup cilantro, coarsely chopped',\n",
    "'4 (6-ounce) mild white fish fillets (for example, cod, hake or blackfish)',\n",
    "'1 (10- to 14-pound) turkey',\n",
    "'1 (10- to 14- pound) turkey',\n",
    "'1 salmon about 4 1/2 pounds, boned with head and tail left on',\n",
    "'1 scallion, chopped, for serving',\n",
    "'1/4 cup/80 grams mild honey',\n",
    "'1 or 2 cup',\n",
    "'5 to 7 handful',\n",
    "'yada yada',\n",
    "'chopped yada yada',\n",
    "'can or jar of stuff',\n",
    "'6c',\n",
    "'[6tsp]',\n",
    "'1 heaping cup',\n",
    "'1 trimmed stalk',\n",
    "'1 can or jar of stuff',\n",
    "'1 can/jar of stuff',\n",
    "'1 can/jar/tin of stuff',\n",
    "'1 can, jar, or tin of stuff',\n",
    "'1 can, jar or tin of stuff',\n",
    "'6dingus 2 cup / 3',\n",
    "'6 2 cup / 3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        n = 1\n",
    "        ts = time()\n",
    "        for _ in range(n):\n",
    "            f(*args, **kw)\n",
    "        te = time()\n",
    "        print ('func: {} took: {:2.4f}ms'.format(f.__name__, (te-ts)*1000/n))\n",
    "        result = f(*args, **kw)\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from parser import devulgarize, strip_html_tags\n",
    "from parser import units_group, TEXT_NUMBERS\n",
    "\n",
    "class Parser:\n",
    "    # TODO: pull all of the functions below into the Parser class\n",
    "\n",
    "    UNIT = 'UNIT'\n",
    "    ALT_UNIT = 'ALT_UNIT'\n",
    "    EA_UNIT = 'EA_UNIT'\n",
    "    QUANTITY = 'QTY'\n",
    "    ALT_QUANTITY = 'ALT_QTY'\n",
    "    EA_QUANTITY = 'EA_QTY'\n",
    "    AMOUNT = 'AMT'\n",
    "    ALT_AMOUNT = 'ALT_AMT'\n",
    "    EA_AMOUNT = 'EA_AMT'\n",
    "    PLUS_AMOUNT = 'PLUS_AMT'\n",
    "    INGREDIENT = 'INGRED'\n",
    "    ALT_INGREDIENT = 'ALT_INGRED'\n",
    "\n",
    "    OPEN_PARENTHESES = ['(', '[']\n",
    "    CLOSE_PARENTHESES = [')', ']']\n",
    "\n",
    "\n",
    "units = r'({})([sei]*)$'.format(units_group)\n",
    "DISREGARD_HEADERS = [\n",
    "    r'accompaniments?:',\n",
    "    r'equipment:',\n",
    "    r'for .*:',\n",
    "    r'garnish(es)?:',\n",
    "    r'glass(ware)?:',\n",
    "    r'grill heat:',\n",
    "    r'ingredient info:',\n",
    "    r'note:',\n",
    "    r'serving suggestion(s)?:',\n",
    "    r'special equipment:',\n",
    "    r'test-kitchen tip:',\n",
    "    r'type of fire:',\n",
    "]\n",
    "\n",
    "def disregard(text: str) -> bool:\n",
    "    \"\"\" Return True if text isn't a \"real\" ingredient\n",
    "    Things that are marked optional remain TBD, but I lean towards disregarding these, too.\n",
    "    \"\"\"\n",
    "\n",
    "    if not text: # empty\n",
    "        return True\n",
    "    if text.endswith(':'):\n",
    "        # Ends in a colon \":\" almost always means it's a directive.\n",
    "        # There are a few cases where a quantity is provided as part of this,\n",
    "        # but this is very rare, and more often than not the quantity is redundant\n",
    "        # with subsequent entries. We'll live with the misses here.\n",
    "        return True\n",
    "    all_parens = r'^\\([^\\)]*\\)$'\n",
    "    if re.match(all_parens, text):\n",
    "        # entirely parenthetical, e.g. \"(Essential oil complement: orange)\"\n",
    "        return True\n",
    "\n",
    "    colon_anywhere = r'.*:.*'\n",
    "    if re.match(colon_anywhere, text):\n",
    "        # check for certain other directives, which typically include a colon, \n",
    "        # e.g. \"Equipment:...\", \"Accompaniment:...\", \"Ingredient info:...\"\n",
    "        lowered = text.lower()\n",
    "        # re.match only considers string start, which is what we want\n",
    "        if any([re.match(pttrn, lowered) for pttrn in DISREGARD_HEADERS]):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "gapless_units = r'(\\d)({})\\b'.format(units_group)\n",
    "def gap_units(text: str) -> str:\n",
    "    # insert a space between quantities and units, e.g. '6c' -> '6 c'\n",
    "    return re.sub(gapless_units, r'\\g<1> \\g<2>', text)\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess/standardize ingredient text in preparation for analysis:\n",
    "        * Strip leading/trailing whitespace\n",
    "        * Strip out any html tags\n",
    "            * At some point, we need to decide the \"correct\" way to handle inlined recipe links and whether we want to do anything about that\n",
    "        * Expand vulgar fractions, prepending a space, e.g. \"1¼\" -> \"1 1/4\" (nltk will take 1/4 as a number, huzzah!)\n",
    "        * Put a space between spaceless units, e.g. \"6c\" -> \"6 c\"\n",
    "        * Convert fractional numbers to decimals (?)\n",
    "    \"\"\"\n",
    "    text = text.strip() # remove leading/trailing whitespace\n",
    "    text = strip_html_tags(text)\n",
    "    text = devulgarize(text)\n",
    "    text = gap_units(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def tokenize(text:str) -> list:\n",
    "    \"\"\" A wrapper on nltk.word_tokenize, except when\n",
    "    we see things like \"grams/3\" in the nltk tokens (e.g. from an ingredient that read\n",
    "    \"45 grams/3 ounces of oil\"), replace it with \"grams\", \"/\", \"3\" so we can use the\n",
    "    slash as an indicator of an alternative measure.\n",
    "    \"\"\"\n",
    "    # tokenize and tag the text usin nltk defaults\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        if '/' not in t:\n",
    "            out += [t]\n",
    "            continue\n",
    "\n",
    "        parts = t.split('/')\n",
    "        digits = len([el for el in parts if el[:1].isdigit() or el[-1:].isdigit()])\n",
    "        if digits == len(parts):\n",
    "            out += [t]\n",
    "            continue\n",
    "\n",
    "        for i, p in enumerate(parts):\n",
    "            if p: # don't include empty strings\n",
    "                out += [p]\n",
    "            if i < len(parts) - 1:\n",
    "                out += ['/']\n",
    "\n",
    "    out = [numerify(el) for el in out]\n",
    "    out = [separate_qualifier_units(el) for el in out]\n",
    "    out = [e for el in out for e in el]\n",
    "\n",
    "    return out\n",
    "\n",
    "def rangeify(tokens: list) -> list:\n",
    "    \"\"\" Convert ranged numbers to their midpoints, e.g.\n",
    "    `6 to 8` -> `7`. This does *not* range units, e.g. it excludes\n",
    "    things like `6 cups to 2 gallons` which is done elsewhere tbd. \n",
    "    Trailing dashes are preserved.\n",
    "    Covered formats:\n",
    "        `6 to 8`\n",
    "        `6-to-8`\n",
    "        `6-to-8-`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    prev_value = None\n",
    "    range_active = False\n",
    "    for token in tokens:\n",
    "        # look for numbers, numbers ending in dashes\n",
    "        dash = ''\n",
    "        if token[-1] == '-':\n",
    "            dash = '-'\n",
    "            token = token[:-1]\n",
    "\n",
    "        if any([cc in token for cc in ['-to-', '-or-']]):\n",
    "            cc = '-to-' if '-to-' in token else '-or-'\n",
    "            parts = token.split(cc)\n",
    "            try:\n",
    "                midpoint = (float(parts[0]) + float(parts[1])) / 2\n",
    "                out += [str(midpoint) + dash]\n",
    "            except ValueError:\n",
    "                out += [token + dash]\n",
    "            range_active = False\n",
    "            prev_value = None\n",
    "\n",
    "        elif token in ['or', 'to']:\n",
    "            range_active = bool(prev_value)\n",
    "            out += [token + dash]\n",
    "\n",
    "        else: # see if it's a number\n",
    "            try:\n",
    "                val = float(token)\n",
    "                if range_active:\n",
    "                    midpoint = (val + prev_value) / 2\n",
    "                    out[-2:] = [str(midpoint) + dash]\n",
    "                    prev_value = None\n",
    "                else:\n",
    "                    out += [str(val) + dash]\n",
    "                    prev_value = val\n",
    "            except ValueError:\n",
    "                out += [token + dash]\n",
    "                prev_value = None\n",
    "            range_active = False\n",
    "\n",
    "    return out\n",
    "\n",
    "def decimate(tokens: list) -> list:\n",
    "    \"\"\" Convert fractions to decimals.\n",
    "    Yes, the method name is cheeky.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    prev_digit = None\n",
    "    for i, t in enumerate(tokens):\n",
    "        dash = ''\n",
    "        if t.endswith('-'):\n",
    "            t = t[:-1]\n",
    "            dash = '-'\n",
    "\n",
    "        parts = t.split('/')\n",
    "        if len(parts) != 2:\n",
    "            out += [t+dash]\n",
    "        \n",
    "        elif all([p.isdigit() for p in parts]):\n",
    "            # `1/2`\n",
    "            val = float(parts[0])/float(parts[1])\n",
    "            if prev_digit:\n",
    "                # sum and overwrite\n",
    "                val += prev_digit\n",
    "                out[-1] = str(val) + dash\n",
    "            else:\n",
    "                out += [str(val) + dash]\n",
    "            \n",
    "        elif parts[1].isdigit() and len(parts[0].split('-')) == 2 and all([p.isdigit() for p in parts[0].split('-')]):\n",
    "            # `1-1/2`\n",
    "            denominator = float(parts[1])\n",
    "            whole, numerator = parts[0].split('-')\n",
    "            val = float(whole) + float(numerator)/denominator\n",
    "            out += [str(val) + dash]\n",
    "\n",
    "        else:\n",
    "            out += [t+dash]\n",
    "\n",
    "        prev_digit = float(t) if t.isdigit() else None\n",
    "\n",
    "    return out\n",
    "\n",
    "def numerify(text: str) -> list:\n",
    "    \"\"\" Convert text numbers to digits \"\"\"\n",
    "    tokens = text.split('-')\n",
    "\n",
    "    if len(tokens) == 1:\n",
    "        # no dashes present; tokens[0] == text\n",
    "        return str(TEXT_NUMBERS.get(text.lower(), text))\n",
    "    elif not any([token.lower() in TEXT_NUMBERS for token in tokens]):\n",
    "        # no numbers\n",
    "        return text\n",
    "\n",
    "    # We have numeric text, which should only be converted to digits if\n",
    "    # it's being used as a quantity (vs, most notably, five-spice powder)\n",
    "    # or a range of quantities.\n",
    "    # This means the token after a number must be either a unit, a range\n",
    "    # indicator (to, or), or empty before we will convert it\n",
    "\n",
    "    if len(tokens) == 2:\n",
    "        if (not tokens[1]) or re.match(units, tokens[1]):\n",
    "            # e.g. \"five-\", \"six-ounce\"\n",
    "            tokens[0] = TEXT_NUMBERS.get(tokens[0].lower(), tokens[0])\n",
    "\n",
    "    elif len(tokens) == 4 and re.match(units, tokens[-1]) and tokens[1].lower() in ['or', 'to']:\n",
    "        # e.g. \"five-to-six-ounce\"\n",
    "        tokens = [TEXT_NUMBERS.get(token.lower(), token) for token in tokens]\n",
    "\n",
    "    return '-'.join([str(t) for t in tokens])\n",
    "\n",
    "def separate_qualifier_units(text: str) -> list:\n",
    "    tokens = text.split('-')\n",
    "    if len(tokens) == 1:\n",
    "        return [text]\n",
    "\n",
    "    if re.match(units, tokens[-1]):\n",
    "        unit = tokens[-1]\n",
    "        tokens[-1] = ''\n",
    "        return '-'.join(tokens), unit\n",
    "    \n",
    "    return [text]\n",
    "\n",
    "def tag_units_and_quantities(tokens: list) -> list:\n",
    "    # tag digit (CD) tokens with the QTY type\n",
    "    # tag units tokens with the UNITS type\n",
    "    out = []\n",
    "    for token in tokens:\n",
    "        if token[1] == 'CD': # digit\n",
    "            # make sure it's actually a digit\n",
    "            try:\n",
    "                float(token[0])\n",
    "                out += [(token[0], Parser.QUANTITY)]\n",
    "            except ValueError:\n",
    "                numeric = ''.join([s for s in token[0] if s in '1234567890.'])\n",
    "                try:\n",
    "                    float(numeric)\n",
    "                    out += [(numeric, Parser.QUANTITY)]\n",
    "                except ValueError:\n",
    "                    out += [token]\n",
    "        elif re.match(units, token[0]):\n",
    "            out += [(token[0], Parser.UNIT)]\n",
    "        else:\n",
    "            out += [token]\n",
    "    return out\n",
    "\n",
    "def coalesce_units(tokens: list) -> list:\n",
    "    # replace [UNIT]/[UNIT]/*, [UNIT] or [UNIT], and [UNIT], [UNIT] with first unit\n",
    "    out = []\n",
    "    prev_unit = False\n",
    "    for token in tokens:\n",
    "        if token[1] == Parser.UNIT:\n",
    "            if prev_unit:\n",
    "                trunc = False\n",
    "                while out[-1][0] in ['/', 'or', ',']:\n",
    "                    out = out[:-1]\n",
    "                    trunc = True\n",
    "                if trunc:\n",
    "                    continue\n",
    "            else:\n",
    "                prev_unit = True\n",
    "        elif prev_unit and token[0] not in ['/', 'or', ',']:\n",
    "            prev_unit = False\n",
    "        out += [token]\n",
    "    return out\n",
    "\n",
    "\n",
    "def tag_amounts(tokens: list) -> list:\n",
    "    # tag quantities that are qualifiers, as identified by a trailing dash,\n",
    "    # tag their subsequent units and EA_UNITS, and aggregate them with\n",
    "    # their units into a EA_AMOUNT. tag non-qualifier amounts as AMOUNT.\n",
    "    out = []\n",
    "    qqr = r'[\\d\\.]+-'\n",
    "    approximators = ['about', 'approx', 'approx.', 'approximately']\n",
    "    skip = False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "        if re.match(qqr, token[0]):\n",
    "            # drop the trailing dash and mark as an EA_QUANTITY\n",
    "            out += [(token[0][:-1], Parser.EA_QUANTITY)]\n",
    "        elif token[1] == Parser.UNIT and i > 0 and out[-1][1] == Parser.QUANTITY:\n",
    "            if len(tokens) > i + 1 and tokens[i+1][0][:4] in ['each']:\n",
    "                out[-1] = [[(out[-1][0], Parser.EA_QUANTITY), (token[0], Parser.EA_UNIT)], Parser.EA_AMOUNT]\n",
    "                # also check for a preceding paired amount and convert to an EA_AMOUNT\n",
    "                # this may not cover all possible cases!\n",
    "                if len(out) > 2 and out[-2][0] in ['/', 'or'] and out[-3][1] == Parser.AMOUNT:\n",
    "                    # mark its paired amount as an EA_AMOUNT\n",
    "                    out[-3] = [out[-3][0], Parser.EA_AMOUNT]\n",
    "                # look for any preceding approximator and remove it\n",
    "                if len(out) > 1 and out[-2][0] in approximators:\n",
    "                    out = out[:-3] + [out[-1]]\n",
    "                skip = True # skip the following 'each'\n",
    "            elif len(out) > 2 and out[-2][0] in approximators:\n",
    "                # check for 'about' or 'approx*' before this, which indicates an ALT_AMOUNT\n",
    "                out[-2] = [[(out[-1][0], Parser.ALT_QUANTITY), (token[0], Parser.ALT_UNIT)], Parser.ALT_AMOUNT]\n",
    "                out = out[:-1]\n",
    "            else:\n",
    "                out[-1] = [[out[-1], token], Parser.AMOUNT]\n",
    "        elif token[1] == Parser.UNIT and i > 0 and out[-1][1] == Parser.EA_QUANTITY:\n",
    "                out[-1] = [[out[-1], (token[0], Parser.EA_UNIT)], Parser.EA_AMOUNT]\n",
    "        else:\n",
    "            out += [token]\n",
    "    return out\n",
    "\n",
    "def strip_qualifier_parens(tokens: list) -> list:\n",
    "    # Remove parentheticals, preserving only qualifier amount(s).\n",
    "    # if the parenthetical starts with \"or AMT\", remove the parentheses but\n",
    "    # otherwise preserve it\n",
    "    paren_indexes = []\n",
    "    cur_paren_index = []\n",
    "    parens_only = False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token[0] in Parser.OPEN_PARENTHESES:\n",
    "            cur_paren_index += [i]\n",
    "            if len(tokens) > i + 2:\n",
    "                if type(tokens[i+1][0]) is str and tokens[i+1][0].lower() in ['or']:\n",
    "                    if tokens[i+2][1] in [Parser.AMOUNT, Parser.ALT_UNIT, Parser.EA_AMOUNT]:\n",
    "                        parens_only = True\n",
    "        elif token[0] in Parser.CLOSE_PARENTHESES:\n",
    "            if cur_paren_index:\n",
    "                cur_paren_index += [i]\n",
    "                paren_indexes += cur_paren_index\n",
    "                cur_paren_index = [] # reset\n",
    "                parens_only = False\n",
    "        elif cur_paren_index and token[1] not in [Parser.EA_AMOUNT, Parser.ALT_AMOUNT, Parser.AMOUNT] and not parens_only:\n",
    "            cur_paren_index += [i]\n",
    "\n",
    "    return [t for i, t in enumerate(tokens) if i not in paren_indexes]\n",
    "\n",
    "def complete_amounts(tokens:list) -> list:\n",
    "    # pull QTY or UNIT values back to orphaned partners, and fill in\n",
    "    # the blanks if none are found\n",
    "    # do not complete orphaned QTYs in parentheticals, as this is usually\n",
    "    # not actually quantity information.\n",
    "    out = []\n",
    "    qty_index = None\n",
    "    unit_index = None\n",
    "    any_qty = False\n",
    "    any_unit = False\n",
    "    any_amt = False\n",
    "    parenthetical = False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token[0] in Parser.OPEN_PARENTHESES:\n",
    "            parenthetical = True\n",
    "        elif parenthetical and token[0] in Parser.CLOSE_PARENTHESES:\n",
    "            parenthetical = False\n",
    "        if token[1] == Parser.UNIT:\n",
    "            any_unit = True\n",
    "            if qty_index is not None:\n",
    "                # this is the unit for the existing qty\n",
    "                out[qty_index] = [[out[qty_index], token], Parser.AMOUNT]\n",
    "                qty_index = None\n",
    "                continue\n",
    "            elif unit_index is not None:\n",
    "                # default to qty 1 for existing unit_index\n",
    "                out[unit_index] = [[('1', Parser.QUANTITY), out[unit_index]], Parser.AMOUNT]\n",
    "            unit_index = len(out)\n",
    "            # out += [token]\n",
    "        elif token[1] == Parser.QUANTITY and not parenthetical:\n",
    "            any_qty = True\n",
    "            if qty_index is not None:\n",
    "                # existing qty is an orphan; default unit to `ea`\n",
    "                out[qty_index] = [[out[qty_index], ('ea', Parser.UNIT)], Parser.AMOUNT]\n",
    "            qty_index = len(out)\n",
    "            # out += [token]\n",
    "        elif token[1] == Parser.AMOUNT:\n",
    "            any_amt = True\n",
    "        out += [token]\n",
    "\n",
    "\n",
    "    # clean up any units/qtys left hanging at the end\n",
    "    if qty_index is not None:\n",
    "        out[qty_index] = [[out[qty_index], ('ea', Parser.UNIT)], Parser.AMOUNT]\n",
    "\n",
    "    if unit_index is not None:\n",
    "        out[unit_index] = [[('1', Parser.QUANTITY), out[unit_index]], Parser.AMOUNT]\n",
    "        if unit_index > 0 and out[unit_index-1][1] == Parser.EA_AMOUNT:\n",
    "            # if hanging unit was preceded by an EA_AMOUNT, flip the AMOUNT before \n",
    "            # the EA_AMOUNT\n",
    "            out[unit_index-1:unit_index+1] = [out[unit_index], out[unit_index-1]]\n",
    "\n",
    "    if not (any_amt or any_unit or any_qty):\n",
    "        out = [[[('1', Parser.QUANTITY), ('ea', Parser.UNIT)], Parser.AMOUNT]] + out\n",
    "\n",
    "    return out\n",
    "\n",
    "def merge_amounts(tokens: list, merge_flavor) -> list:\n",
    "    # link ALT_AMOUNTs to their parent AMOUNT or EA_AMOUNT,\n",
    "    # and link EA_AMOUNTS to their parent AMOUNT\n",
    "    out = []\n",
    "    prev_par_index = None\n",
    "\n",
    "    for _, token in enumerate(tokens):\n",
    "        if not token[1] == merge_flavor:\n",
    "            out += [token]\n",
    "\n",
    "        if token[1] == merge_flavor:\n",
    "            if prev_par_index is not None:\n",
    "                out[prev_par_index][0] += [token]\n",
    "            else:\n",
    "                out += [token]\n",
    "        elif token[1] in [Parser.AMOUNT, Parser.EA_AMOUNT]:\n",
    "            # order of this and previous elif matter because EA_AMOUNT\n",
    "            # cannot be a parent if its the merge_flavor\n",
    "            prev_par_index = len(out) - 1\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def plus_amounts(tokens: list) -> list:\n",
    "    # If we find the pattern [AMT, 'plus', AMT], append the second\n",
    "    # AMT to the first one and change its type to Parser.PLUS_AMOUNT\n",
    "    out = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token[1] in [Parser.AMOUNT]:\n",
    "            # handle this via lookbehind\n",
    "            if i > 1:\n",
    "                prev_token = tokens[i-1][0]\n",
    "                if type(prev_token) is str and prev_token.lower() in ['plus']:\n",
    "                    prev_prev_token = tokens[i-2]\n",
    "                    if prev_prev_token[1] in [Parser.AMOUNT]:\n",
    "                        out[-2][0] += [(token[0], Parser.PLUS_AMOUNT)]\n",
    "                        out = out[:-1]\n",
    "                        continue\n",
    "        out += [token]\n",
    "    return out\n",
    "\n",
    "def strip_remnants(tokens: list) -> list:\n",
    "    # Remove leftover things like slashes that separated amounts.\n",
    "    # Currently looks for slashes and 'of'\n",
    "    out = []\n",
    "    prev_flavor = None\n",
    "\n",
    "    for token in tokens:\n",
    "        if token[0] in ['/', 'of'] and prev_flavor in [Parser.AMOUNT, Parser.EA_AMOUNT, Parser.ALT_AMOUNT]:\n",
    "            continue\n",
    "        out += [token]\n",
    "        prev_flavor = token[1]\n",
    "\n",
    "    return out\n",
    "\n",
    "def label_ingredients(tokens: list) -> list:\n",
    "    # Sometimes an ingredient line contains two separate ingredients,\n",
    "    # usually because the second one is provided as an alternative.\n",
    "    # Here, we wrap ingredients in either Parser.INGREDIENT or Parser.ALT_INGREDIENT\n",
    "    # tags if full ingredients are separated by an 'or' token.\n",
    "    # This has quite limited capabilities and will need to be evolved.\n",
    "    ingred = []\n",
    "    ingred_amt = False\n",
    "    ingred_name = False\n",
    "    or_index = None\n",
    "    out = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token[1] in [Parser.AMOUNT, Parser.ALT_AMOUNT, Parser.EA_AMOUNT]:\n",
    "            if ingred_amt and ingred_name and (or_index is not None):\n",
    "                # we've already parsed a full ingredient\n",
    "                if out:\n",
    "                    out += [[ingred, Parser.ALT_INGREDIENT]]\n",
    "                else:\n",
    "                    del ingred[or_index]\n",
    "                    out += [[ingred, Parser.INGREDIENT]]\n",
    "                ingred = [] # reset\n",
    "                ingred_name = False\n",
    "                or_index = None\n",
    "            ingred_amt = True\n",
    "        elif type(token[1]) is str:\n",
    "            if token[1].startswith('NN'):\n",
    "                ingred_name = True\n",
    "            elif token[0].lower() == 'or' and ingred_name and ingred_amt:\n",
    "                # only count this if we've seen the rest of the ingredient\n",
    "                or_index = len(ingred)\n",
    "\n",
    "        if token[1] in [Parser.AMOUNT, Parser.ALT_AMOUNT, Parser.EA_AMOUNT] and not ingred_amt:\n",
    "            ingred = [token] + ingred # prepend egads what?\n",
    "        else:\n",
    "            ingred += [token]\n",
    "    \n",
    "    if ingred:\n",
    "        flavor = Parser.ALT_INGREDIENT if out else Parser.INGREDIENT\n",
    "        out += [[ingred, flavor]]\n",
    "    \n",
    "    return out\n",
    "\n",
    "def focus(ingredient: list) -> list:\n",
    "    # Remove extraneous things like prep mods and unhelpful descriptions.\n",
    "    # This is mostly done using parts of speech and their position in the ingredient.\n",
    "    # We call this recursively as we eliminate unhelpful bits.\n",
    "    ingred = ingredient[0]\n",
    "    pos_distractions = ['VBD', 'VBN', 'IN', 'DT']\n",
    "    distractions = ['preferably']\n",
    "\n",
    "    if ingred[-1][0] in [',', ';']:\n",
    "        # eliminate dangling punctuation\n",
    "        ingred = ingred[:-1]\n",
    "        return focus([ingred, ingredient[1]])\n",
    "\n",
    "    first_noun = [i for i in range(len(ingred)) if type(ingred[i][1]) is str and ingred[i][1].startswith('NN')]\n",
    "    first_noun = min(first_noun) if first_noun else 0\n",
    "\n",
    "    # find the comma indexes, which often delineate phrases\n",
    "    commas = [i for i in range(len(ingred)) if ingred[i][0] in [','] and i > first_noun]\n",
    "    if commas:\n",
    "        # TODO: this bails as soon as it finds one useful phrase; it should continue to\n",
    "        # backtrack and see if there's anything else to snip out!\n",
    "        phrase = ingred[commas[-1]+1:]\n",
    "        if phrase[0][1] in pos_distractions or phrase[-1][1] in pos_distractions or phrase[0][0] in distractions:\n",
    "            ingred = ingred[:commas[-1]]\n",
    "            return focus([ingred, ingredient[1]])\n",
    "\n",
    "\n",
    "    # fix cruft in the lede phrase\n",
    "    noun_seen = False\n",
    "    distraction_start = None\n",
    "    lede_pos_distractions = ['VBD', 'VBN', 'DT']\n",
    "    lede_destractions = ['in']\n",
    "    \n",
    "    for i, el in enumerate(ingred):\n",
    "        if not noun_seen and type(el[1]) is str and el[1].startswith('NN'):\n",
    "            noun_seen = True\n",
    "        elif noun_seen and (distraction_start is None) and (el[1] in lede_pos_distractions or el[0] in lede_destractions):\n",
    "            # print('distraction found:', el[1])\n",
    "            distraction_start = i\n",
    "        elif noun_seen and el[0] == ',':\n",
    "            break\n",
    "\n",
    "    if distraction_start is not None:\n",
    "        # print('ingred[:distraction_start]', ingred[:distraction_start])\n",
    "        # print('ingred[i:]', ingred[i:])\n",
    "        ingred = ingred[:distraction_start] + ingred[i+1:]\n",
    "\n",
    "    # there can also be cruft prior to the lede phrase; remove it\n",
    "    prior_phrases = [i for i in range(len(ingred)) if ingred[i][0] in [','] and i < first_noun]\n",
    "    non_amts = [i for i in range(len(ingred)) if ingred[i][1] not in [Parser.AMOUNT, Parser.EA_AMOUNT, Parser.ALT_AMOUNT]]\n",
    "    non_amt_start = min(non_amts) if non_amts else None\n",
    "    if prior_phrases and (non_amt_start is not None):\n",
    "        # print('pre-cruft available to kill!!!')\n",
    "        phrase = ingred[non_amt_start:prior_phrases[0]+1]\n",
    "        # print('phrase', phrase)\n",
    "        if len(phrase)==1 or phrase[0][1] in distractions or phrase[-1][1] in distractions:\n",
    "            # print('snipping!')\n",
    "            # snip it out\n",
    "            ingred = ingred[:non_amt_start] + ingred[prior_phrases[0]+1:]\n",
    "            # print(ingred)\n",
    "            return focus([ingred, ingredient[1]])\n",
    "\n",
    "\n",
    "    return [ingred, ingredient[1]]\n",
    "\n",
    "def retag(ingredient:list) -> list:\n",
    "    # we want to parse as big of chunks as we can to maximize the\n",
    "    # info we give to nltk. \n",
    "    # Find any ingredient bits that aren't strings!\n",
    "    non_string_indexes = [i for i in range(len(ingredient[0])) if type(ingredient[0][i][0]) is not str]\n",
    "    # now, move pairwise through the non_string_index values, re-tagging\n",
    "    # whatever's in between those indexes\n",
    "    prev = 0\n",
    "    for i in non_string_indexes:\n",
    "        ingredient[0][prev:i] = nltk.pos_tag([ing[0] for ing in ingredient[0][prev:i]])\n",
    "        prev = i + 1\n",
    "    ingredient[0][prev:] = nltk.pos_tag([ing[0] for ing in ingredient[0][prev:]])\n",
    "    return ingredient\n",
    "\n",
    "    \n",
    "\n",
    "def tag_alt_amounts(tokens: list) -> list:\n",
    "    # tag alt amounts indicated by amounts after amounts, either in parentheses or separated by slashes\n",
    "    out = []\n",
    "    prev_type = None\n",
    "    alt_active = False\n",
    "    multiple_alts = False\n",
    "    for token in tokens:\n",
    "        if prev_type not in [Parser.AMOUNT, Parser.ALT_AMOUNT, Parser.EA_AMOUNT]:\n",
    "            prev_type = token[1]\n",
    "    \n",
    "        elif token[0] in ['(', '[', '/', 'or']:\n",
    "            alt_active = True\n",
    "            multiple_alts = token[0] in ['(', '[']\n",
    "\n",
    "        elif not alt_active:\n",
    "            prev_type = token[1]\n",
    "            \n",
    "        elif token[1] == Parser.AMOUNT:\n",
    "            # retag it as an ALT_AMOUNT incl. ALT_QUANTITY and ALT_UNIT\n",
    "            for i in range(len(token[0])):\n",
    "                if token[0][i][1] == Parser.QUANTITY:\n",
    "                    token[0][i] = (token[0][i][0], Parser.ALT_QUANTITY)\n",
    "                elif token[0][i][1] == Parser.UNIT:\n",
    "                    token[0][i] = (token[0][i][0], Parser.ALT_UNIT)\n",
    "            token[1] = Parser.ALT_AMOUNT\n",
    "                    \n",
    "            if not multiple_alts:\n",
    "                alt_active = False\n",
    "                multiple_alts = False\n",
    "\n",
    "        elif token[0] in [')', ']']:\n",
    "            alt_active = False\n",
    "            multiple_alts = False\n",
    "\n",
    "        out += [token]\n",
    "\n",
    "    return out\n",
    "\n",
    "def tag(tokens: list) -> list:\n",
    "    # this is the main semantic undertaking\n",
    "    data = nltk.pos_tag(tokens)\n",
    "    # print('0:', data, '\\n')\n",
    "    data = tag_units_and_quantities(data)\n",
    "    # print('1:', data, '\\n')\n",
    "    data = coalesce_units(data)\n",
    "    # print('2:', data, '\\n')\n",
    "    data = tag_amounts(data)\n",
    "    # print('3:', data, '\\n')\n",
    "    data = tag_alt_amounts(data)\n",
    "    # print('4:', data, '\\n')\n",
    "    data = complete_amounts(data)\n",
    "    # print('5:', data, '\\n')\n",
    "    data = merge_amounts(data, Parser.ALT_AMOUNT)\n",
    "    # print('6:', data, '\\n')\n",
    "    data = merge_amounts(data, Parser.EA_AMOUNT)\n",
    "    # print('7:', data, '\\n')\n",
    "    data = strip_qualifier_parens(data)\n",
    "    # print('8:', data, '\\n')\n",
    "    data = strip_remnants(data)\n",
    "    # print('strip_remnants:', data, '\\n')\n",
    "    data = plus_amounts(data)\n",
    "    # print('plus_amounts:', data, '\\n')\n",
    "    data = label_ingredients(data)\n",
    "    # re-pos_tag the leftovers, as nltk doesn't do a great job when ingredient data is mixed in,\n",
    "    # and we want the most accurate POS values for the focus() call that follows.\n",
    "    # print('label_ingredients:', data, '\\n')\n",
    "    data = [retag(d) for d in data]\n",
    "    # print('retag:', data, '\\n')\n",
    "    data = [focus(d) for d in data]\n",
    "    # print('focus:', data, '\\n')\n",
    "    return data\n",
    "\n",
    "def standardize_unit(unit):\n",
    "    from parser import UNITS\n",
    "    if unit in UNITS:\n",
    "        return UNITS[unit]\n",
    "    elif unit[-1] == 's' and unit[:-1] in UNITS:\n",
    "        return UNITS[unit[:-1]]\n",
    "    elif unit[:-2] == 'es' and unit[:-2] in UNITS:\n",
    "        return UNITS[unit[:-2]]\n",
    "\n",
    "\n",
    "def quantify(amount):\n",
    "    \"\"\" Convert a Parser.AMOUNT object into a mass, volume, or `each` quantity,\n",
    "    return a (quantity, unit) tuple. mass's unit is `g`, volume is `ml`,\n",
    "    and each is `each`.\n",
    "\n",
    "    Mass is preferred to volume; volume is preferred to `each`. Parse the amount,\n",
    "    and standardize it to the most preferred option available.\n",
    "    \"\"\"\n",
    "    from convert import Convert\n",
    "    qty, unit = None, None\n",
    "    # print('quantify:', amount)\n",
    "    for el in amount[:2]:\n",
    "        if len(el) > 1:\n",
    "            if el[1] in [Parser.QUANTITY, Parser.EA_QUANTITY, Parser.ALT_QUANTITY]:\n",
    "                qty = float(el[0])\n",
    "            elif el[1] in [Parser.UNIT, Parser.EA_UNIT, Parser.ALT_UNIT]:\n",
    "                unit = el[0]\n",
    "        \n",
    "    unit = standardize_unit(unit)\n",
    "    if unit in Convert.VOLUME:\n",
    "        qty *= Convert.VOLUME[unit]\n",
    "        unit = 'ml'\n",
    "\n",
    "    elif unit in Convert.MASS:\n",
    "        qty *= Convert.MASS[unit]\n",
    "        unit = 'g'\n",
    "\n",
    "    alt_amount = None\n",
    "    plus_amount = None\n",
    "    ea_amount = None\n",
    "    for extra in amount[2:]:\n",
    "        # print(extra)\n",
    "        if extra[1] == Parser.ALT_AMOUNT:\n",
    "            alt_amount = quantify(extra[0])\n",
    "        elif extra[1] == Parser.EA_AMOUNT:\n",
    "            ea_amount = quantify(extra[0])\n",
    "        elif extra[1] == Parser.PLUS_AMOUNT:\n",
    "            plus_amount = quantify(extra[0])\n",
    "\n",
    "    # the order here matters, as we want to convert in reverse\n",
    "    # order of priority, so that, for example, `ea` values get swapped out\n",
    "    # before we assess `g`-specific modifications\n",
    "    if unit in ['ea', 'pkg']:\n",
    "        # print('unit is `ea`')\n",
    "        if ea_amount:\n",
    "            qty *= ea_amount[0]\n",
    "            unit = ea_amount[1]\n",
    "        elif alt_amount and alt_amount[1] in ['g', 'ml']:\n",
    "            qty, unit = alt_amount\n",
    "\n",
    "    if unit == 'ml':\n",
    "        # print('unit is `ml`')\n",
    "        if alt_amount and alt_amount[1] == 'g':\n",
    "            qty, unit = alt_amount\n",
    "        elif plus_amount and plus_amount[1] == 'ml':\n",
    "            qty += plus_amount[0]\n",
    "    \n",
    "    if unit == 'g':\n",
    "        # if we have a mass value, we only care about plus_amounts\n",
    "        # print('unit is `g`; plus_amount is', plus_amount)\n",
    "        if plus_amount and plus_amount[1] == 'g':\n",
    "            # print('adding plus amount')\n",
    "            qty += plus_amount[0]\n",
    "\n",
    "    # else:\n",
    "    #     print('unit is something weird:', unit)\n",
    "\n",
    "    # print('quantified:', qty, unit)\n",
    "    # print('alt_amount:', alt_amount)\n",
    "    # print('ea_amount:', ea_amount)\n",
    "    # print('plus_amount:', plus_amount, '\\n')\n",
    "    return qty, unit\n",
    "\n",
    "def detokenize(ingredient_tokens):\n",
    "    # convert tokens to a string (for human readability)\n",
    "    out = ''\n",
    "    if not ingredient_tokens:\n",
    "        return out\n",
    "    for ingred in ingredient_tokens:\n",
    "        # print('INGRED::')\n",
    "        try:\n",
    "            tokens = ingred[0]\n",
    "        except Exception as err:\n",
    "            print(ingred)\n",
    "            raise err\n",
    "        for t in tokens:\n",
    "            if out and t[1] not in [',']:\n",
    "                out += ' '\n",
    "            if t[1] in [Parser.AMOUNT]:\n",
    "                out += '{} {}'.format(*quantify(t[0]))\n",
    "                # continue # TODO: reduce it to it's canonical representation\n",
    "            else:\n",
    "                try:\n",
    "                    out += t[0]\n",
    "                except Exception as err:\n",
    "                    print(t)\n",
    "                    raise err\n",
    "    return out\n",
    "\n",
    "# @timing\n",
    "def parse(raw_text: str):\n",
    "    \"\"\" Extract quantity and name information from an ingredient entry\n",
    "    \"\"\"\n",
    "    text = preprocess(raw_text)\n",
    "    if disregard(text):\n",
    "        return None\n",
    "\n",
    "    tokens = tokenize(text)\n",
    "    tokens = decimate(tokens)\n",
    "    tokens = rangeify(tokens)\n",
    "\n",
    "    tagged_data = tag(tokens)\n",
    "    # TODO: figure out what to do about \"for example\", \"like\", \"such as\" phrases\n",
    "    # TODO: rip out stopwords\n",
    "    # TODO: teach the matcher to look at the last NN* before the first (if any) comma after the AMT.\n",
    "    # That is almost always your guy, and then you could move back if there were alternatives. We'll need to futz this,\n",
    "    # but I think having the POS structure and the AMT cleanly extracted is a game changer.\n",
    "\n",
    "    return tagged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: 4 large (8 to 9 ounces each) chicken breast halves, each cut in half crosswise to make 8 pieces total\n",
      "PARSED: [[[[[('4.0', 'QTY'), ('ea', 'UNIT'), [[('8.5', 'EA_QTY'), ('ounces', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('large', 'JJ'), ('chicken', 'NN'), ('breast', 'NN'), ('halves', 'NNS')], 'INGRED']]\n",
      "OUT: 963.8829999999999 g large chicken breast halves \n",
      "\n",
      "IN: 1¼ cup/80 grams plus 2 teaspoons/5 grams mild honey\n",
      "PARSED: [[[[[('1.25', 'QTY'), ('cup', 'UNIT'), [[('80.0', 'ALT_QTY'), ('grams', 'ALT_UNIT')], 'ALT_AMT'], ([('2.0', 'QTY'), ('teaspoons', 'UNIT'), [[('5.0', 'ALT_QTY'), ('grams', 'ALT_UNIT')], 'ALT_AMT']], 'PLUS_AMT')], 'AMT'], ('mild', 'JJ'), ('honey', 'NN')], 'INGRED']]\n",
      "OUT: 85.0 g mild honey \n",
      "\n",
      "IN: 1/2 pound fresh tuna, grilled or 6 1/2- to 7-ounce can albacore tuna, packed in water\n",
      "PARSED: [[[[[('0.5', 'QTY'), ('pound', 'UNIT')], 'AMT'], ('fresh', 'JJ'), ('tuna', 'NN')], 'INGRED'], [[[[('1', 'QTY'), ('can', 'UNIT'), [[('6.75', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('albacore', 'RB'), ('tuna', 'NN')], 'ALT_INGRED']]\n",
      "OUT: 226.796 g fresh tuna 191.359125 g albacore tuna \n",
      "\n",
      "IN: 1 salmon or other firm fish, about 2 pounds, gutted and scaled, with the head left on\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('2.0', 'ALT_QTY'), ('pounds', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('salmon', 'NN'), ('or', 'CC'), ('other', 'JJ'), ('firm', 'JJ'), ('fish', 'NN')], 'INGRED']]\n",
      "OUT: 907.184 g salmon or other firm fish \n",
      "\n",
      "IN: 4 whole fish, like sea bass or black bass, 1 to 1 1/2 pounds each\n",
      "PARSED: [[[[[('4.0', 'QTY'), ('ea', 'UNIT'), [[('1.25', 'EA_QTY'), ('pounds', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('whole', 'JJ'), ('fish', 'NN')], 'INGRED']]\n",
      "OUT: 2267.96 g whole fish \n",
      "\n",
      "IN: 4 whole fish,, like sea bass or black bass, 1 to 1.5 pounds each\n",
      "PARSED: [[[[[('4.0', 'QTY'), ('ea', 'UNIT'), [[('1.25', 'EA_QTY'), ('pounds', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('whole', 'JJ'), ('fish', 'NN')], 'INGRED']]\n",
      "OUT: 2267.96 g whole fish \n",
      "\n",
      "IN: 2 cans (10 ounces each) of condensed cream of celery or cream of mushroom soup\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('cans', 'UNIT'), [[('10.0', 'EA_QTY'), ('ounces', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('condensed', 'JJ'), ('cream', 'NN'), ('of', 'IN'), ('celery', 'NN'), ('or', 'CC'), ('cream', 'NN'), ('of', 'IN'), ('mushroom', 'NN'), ('soup', 'NN')], 'INGRED']]\n",
      "OUT: 566.99 g condensed cream of celery or cream of mushroom soup \n",
      "\n",
      "IN: 2 cans (10 ounces/280 grams each) of condensed cream of celery or cream of mushroom soup\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('cans', 'UNIT'), [[('10.0', 'QTY'), ('ounces', 'UNIT')], 'EA_AMT'], [[('280.0', 'EA_QTY'), ('grams', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('condensed', 'JJ'), ('cream', 'NN'), ('of', 'IN'), ('celery', 'NN'), ('or', 'CC'), ('cream', 'NN'), ('of', 'IN'), ('mushroom', 'NN'), ('soup', 'NN')], 'INGRED']]\n",
      "OUT: 560.0 g condensed cream of celery or cream of mushroom soup \n",
      "\n",
      "IN: 1 six-to-eight-pound, cleaned, whole salmon, preferably with head left on (see note)\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('7.0', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('cleaned', 'VBD'), (',', ','), ('whole', 'JJ'), ('salmon', 'NN')], 'INGRED']]\n",
      "OUT: 3175.144 g cleaned, whole salmon \n",
      "\n",
      "IN: Two 5-ounce (140g) cans tuna in olive oil, drained (or 10 ounces/280g shredded roast chicken meat)\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('cans', 'UNIT'), [[('5.0', 'EA_QTY'), ('ounce', 'EA_UNIT'), [[('140.0', 'ALT_QTY'), ('g', 'ALT_UNIT')], 'ALT_AMT']], 'EA_AMT']], 'AMT'], ('tuna', 'NN')], 'INGRED'], [[[[('10.0', 'QTY'), ('ounces', 'UNIT'), [[('280.0', 'ALT_QTY'), ('g', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('shredded', 'VBN'), ('roast', 'NN'), ('chicken', 'NN'), ('meat', 'NN')], 'ALT_INGRED']]\n",
      "OUT: 283.495 g tuna 283.495 g shredded roast chicken meat \n",
      "\n",
      "IN: 1 (5-ounce) can tuna packed in olive oil, preferably Italian (see note)\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT'), [[('5.0', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('tuna', 'NN')], 'INGRED']]\n",
      "OUT: 141.7475 g tuna \n",
      "\n",
      "IN: unsalted, softened butter, softened: 9 tablespoons (4.5 ounces or 128 grams)\n",
      "PARSED: [[[('unsalted', 'JJ'), (',', ','), ('softened', 'JJ'), ('butter', 'NN')], 'INGRED']]\n",
      "OUT: unsalted, softened butter \n",
      "\n",
      "IN: 1 pound boneless, skinless chicken breast, cut across the grain in 1/4-inch thick slices\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('pound', 'UNIT')], 'AMT'], ('boneless', 'NN'), (',', ','), ('skinless', 'NN'), ('chicken', 'NN'), ('breast', 'NN')], 'INGRED']]\n",
      "OUT: 453.592 g boneless, skinless chicken breast \n",
      "\n",
      "IN: grape or cherry tomatoes\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('grape', 'NN'), ('or', 'CC'), ('cherry', 'NN'), ('tomatoes', 'NNS')], 'INGRED']]\n",
      "OUT: 1.0 ea grape or cherry tomatoes \n",
      "\n",
      "IN: grape or cherry tomato\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('grape', 'NN'), ('or', 'CC'), ('cherry', 'NN'), ('tomato', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 ea grape or cherry tomato \n",
      "\n",
      "IN: ripe or green cherry tomato\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('ripe', 'NN'), ('or', 'CC'), ('green', 'JJ'), ('cherry', 'NN'), ('tomato', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 ea ripe or green cherry tomato \n",
      "\n",
      "IN: 2 4-pound Atlantic salmon (2 1/4 inches at thickest point), scaled and cleaned, gills removed, head and tail on, interior cavity well washed\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('ea', 'UNIT'), [[('4.0', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('Atlantic', 'NNP'), ('salmon', 'NN')], 'INGRED']]\n",
      "OUT: 3628.736 g Atlantic salmon \n",
      "\n",
      "IN: 2 cotechini (Italian garlic sausages), about 1 pound each (available at Italian butcher shops)\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('ea', 'UNIT'), [[('1.0', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('cotechini', 'NN')], 'INGRED']]\n",
      "OUT: 907.184 g cotechini \n",
      "\n",
      "IN: 1¼ cup/80 grams mild honey\n",
      "PARSED: [[[[[('1.25', 'QTY'), ('cup', 'UNIT'), [[('80.0', 'ALT_QTY'), ('grams', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('mild', 'JJ'), ('honey', 'NN')], 'INGRED']]\n",
      "OUT: 80.0 g mild honey \n",
      "\n",
      "IN: 1 (5- or 6-ounce) can or jar tuna, drained and flaked, or 1 (13-ounce) can chickpeas or white beans, drained\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT'), [[('5.5', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('tuna', 'NN')], 'INGRED'], [[[[('1.0', 'QTY'), ('can', 'UNIT'), [[('13.0', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('chickpeas', 'NNS'), ('or', 'CC'), ('white', 'JJ'), ('beans', 'NNS')], 'ALT_INGRED']]\n",
      "OUT: 155.92225 g tuna 368.5435 g chickpeas or white beans \n",
      "\n",
      "IN: 2 (6-ounce) cans Italian tuna in water or oil, drained\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('cans', 'UNIT'), [[('6.0', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('Italian', 'JJ'), ('tuna', 'NN')], 'INGRED']]\n",
      "OUT: 340.19399999999996 g Italian tuna \n",
      "\n",
      "IN: 1 (4-ounce) can smoked mussels\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT'), [[('4.0', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('smoked', 'VBN'), ('mussels', 'NNS')], 'INGRED']]\n",
      "OUT: 113.398 g smoked mussels \n",
      "\n",
      "IN: 1¼ cup (approx. 80 grams) mild honey\n",
      "PARSED: [[[[[('1.25', 'QTY'), ('cup', 'UNIT'), [[('80.0', 'ALT_QTY'), ('grams', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('mild', 'JJ'), ('honey', 'NN')], 'INGRED']]\n",
      "OUT: 80.0 g mild honey \n",
      "\n",
      "IN: 350g (approx. 1 1/2 cups) mild honey\n",
      "PARSED: [[[[[('350.0', 'QTY'), ('g', 'UNIT'), [[('1.5', 'ALT_QTY'), ('cups', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('mild', 'JJ'), ('honey', 'NN')], 'INGRED']]\n",
      "OUT: 350.0 g mild honey \n",
      "\n",
      "IN: 4 boneless, skinless chicken breasts (6 to 8 ounces each)\n",
      "PARSED: [[[[[('4.0', 'QTY'), ('ea', 'UNIT'), [[('7.0', 'EA_QTY'), ('ounces', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('boneless', 'NN'), (',', ','), ('skinless', 'NN'), ('chicken', 'NN'), ('breasts', 'NNS')], 'INGRED']]\n",
      "OUT: 793.786 g boneless, skinless chicken breasts \n",
      "\n",
      "IN: 2 medium-size tomatoes, each seeded and cut into 6 pieces\n",
      "PARSED: [[[[[('2.0', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('medium-size', 'NN'), ('tomatoes', 'NNS')], 'INGRED']]\n",
      "OUT: 2.0 ea medium-size tomatoes \n",
      "\n",
      "IN: handful peanuts\n",
      "PARSED: [[[[[('1', 'QTY'), ('handful', 'UNIT')], 'AMT'], ('peanuts', 'NNS')], 'INGRED']]\n",
      "OUT: 118.0 ml peanuts \n",
      "\n",
      "IN: chopped parsley\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('chopped', 'VBN'), ('parsley', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 ea chopped parsley \n",
      "\n",
      "IN: 1-1/2 tablespoons Dijon mustard\n",
      "PARSED: [[[[[('1.5', 'QTY'), ('tablespoons', 'UNIT')], 'AMT'], ('Dijon', 'NNP'), ('mustard', 'NN')], 'INGRED']]\n",
      "OUT: 22.1802 ml Dijon mustard \n",
      "\n",
      "IN: 5-to-6-pound, cleaned, whole salmon, preferably with head left on (see note)\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT'), [[('5.5', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('cleaned', 'VBD'), (',', ','), ('whole', 'JJ'), ('salmon', 'NN')], 'INGRED']]\n",
      "OUT: 2494.756 g cleaned, whole salmon \n",
      "\n",
      "IN: 1 5-to-6-pound, cleaned, whole salmon, preferably with head left on (see note)\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('5.5', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('cleaned', 'VBD'), (',', ','), ('whole', 'JJ'), ('salmon', 'NN')], 'INGRED']]\n",
      "OUT: 2494.756 g cleaned, whole salmon \n",
      "\n",
      "IN: 1 five- to six-pound, cleaned, whole salmon, preferably with head left on (see note)\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('5.5', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('cleaned', 'VBD'), (',', ','), ('whole', 'JJ'), ('salmon', 'NN')], 'INGRED']]\n",
      "OUT: 2494.756 g cleaned, whole salmon \n",
      "\n",
      "IN: 1 (1 1/2-pound) salmon fillet, skin-on or skinless\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('fillet', 'UNIT'), [[('1.5', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('salmon', 'NN'), (',', ','), ('skin-on', 'JJ'), ('or', 'CC'), ('skinless', 'NN')], 'INGRED']]\n",
      "OUT: 680.3879999999999 g salmon, skin-on or skinless \n",
      "\n",
      "IN: 6 cup\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('cup', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 1419.528 ml \n",
      "\n",
      "IN: 6 cups\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('cups', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 1419.528 ml \n",
      "\n",
      "IN: 6 cups <a href=\"https://cooking.nytimes.com/recipes/1021916-vegan-bolognese\">vegan Bolognese</a>\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('cups', 'UNIT')], 'AMT'], ('vegan', 'NNS'), ('Bolognese', 'JJ')], 'INGRED']]\n",
      "OUT: 1419.528 ml vegan Bolognese \n",
      "\n",
      "IN: 1 cup flour\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('cup', 'UNIT')], 'AMT'], ('flour', 'NN')], 'INGRED']]\n",
      "OUT: 236.588 ml flour \n",
      "\n",
      "IN: 1 c flour\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('c', 'UNIT')], 'AMT'], ('flour', 'NN')], 'INGRED']]\n",
      "OUT: 236.588 ml flour \n",
      "\n",
      "IN: 1.5c flour\n",
      "PARSED: [[[[[('1.5', 'QTY'), ('c', 'UNIT')], 'AMT'], ('flour', 'NN')], 'INGRED']]\n",
      "OUT: 354.882 ml flour \n",
      "\n",
      "IN: 1 1/2c flour\n",
      "PARSED: [[[[[('1.5', 'QTY'), ('c', 'UNIT')], 'AMT'], ('flour', 'NN')], 'INGRED']]\n",
      "OUT: 354.882 ml flour \n",
      "\n",
      "IN: For the filling:  \n",
      "PARSED: None\n",
      "OUT:  \n",
      "\n",
      "IN: 1 packed cup cilantro, coarsely chopped\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('cup', 'UNIT')], 'AMT'], ('packed', 'VBN'), ('cilantro', 'NN')], 'INGRED']]\n",
      "OUT: 236.588 ml packed cilantro \n",
      "\n",
      "IN: 4 (6-ounce) mild white fish fillets (for example, cod, hake or blackfish)\n",
      "PARSED: [[[[[('4.0', 'QTY'), ('fillets', 'UNIT'), [[('6.0', 'EA_QTY'), ('ounce', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('mild', 'JJ'), ('white', 'JJ'), ('fish', 'NN')], 'INGRED']]\n",
      "OUT: 680.3879999999999 g mild white fish \n",
      "\n",
      "IN: 1 (10- to 14-pound) turkey\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('12.0', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('turkey', 'NN')], 'INGRED']]\n",
      "OUT: 5443.103999999999 g turkey \n",
      "\n",
      "IN: 1 (10- to 14- pound) turkey\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('12.0', 'EA_QTY'), ('pound', 'EA_UNIT')], 'EA_AMT']], 'AMT'], ('turkey', 'NN')], 'INGRED']]\n",
      "OUT: 5443.103999999999 g turkey \n",
      "\n",
      "IN: 1 salmon about 4 1/2 pounds, boned with head and tail left on\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT'), [[('4.5', 'ALT_QTY'), ('pounds', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('salmon', 'NN')], 'INGRED']]\n",
      "OUT: 2041.164 g salmon \n",
      "\n",
      "IN: 1 scallion, chopped, for serving\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('scallion', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 ea scallion \n",
      "\n",
      "IN: 1/4 cup/80 grams mild honey\n",
      "PARSED: [[[[[('0.25', 'QTY'), ('cup', 'UNIT'), [[('80.0', 'ALT_QTY'), ('grams', 'ALT_UNIT')], 'ALT_AMT']], 'AMT'], ('mild', 'JJ'), ('honey', 'NN')], 'INGRED']]\n",
      "OUT: 80.0 g mild honey \n",
      "\n",
      "IN: 1 or 2 cup\n",
      "PARSED: [[[[[('1.5', 'QTY'), ('cup', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 354.882 ml \n",
      "\n",
      "IN: 5 to 7 handful\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('handful', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 708.0 ml \n",
      "\n",
      "IN: yada yada\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('yada', 'NN'), ('yada', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 ea yada yada \n",
      "\n",
      "IN: chopped yada yada\n",
      "PARSED: [[[[[('1', 'QTY'), ('ea', 'UNIT')], 'AMT'], ('chopped', 'VBN'), ('yada', 'CD'), ('yada', 'NNS')], 'INGRED']]\n",
      "OUT: 1.0 ea chopped yada yada \n",
      "\n",
      "IN: can or jar of stuff\n",
      "PARSED: [[[[[('1', 'QTY'), ('can', 'UNIT')], 'AMT'], ('stuff', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 pkg stuff \n",
      "\n",
      "IN: 6c\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('c', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 1419.528 ml \n",
      "\n",
      "IN: [6tsp]\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('tsp', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 29.57352 ml \n",
      "\n",
      "IN: 1 heaping cup\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('cup', 'UNIT')], 'AMT'], ('heaping', 'VBG')], 'INGRED']]\n",
      "OUT: 236.588 ml heaping \n",
      "\n",
      "IN: 1 trimmed stalk\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('stalk', 'UNIT')], 'AMT'], ('trimmed', 'VBN')], 'INGRED']]\n",
      "OUT: 1.0 ea trimmed \n",
      "\n",
      "IN: 1 can or jar of stuff\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT')], 'AMT'], ('stuff', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 pkg stuff \n",
      "\n",
      "IN: 1 can/jar of stuff\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT')], 'AMT'], ('stuff', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 pkg stuff \n",
      "\n",
      "IN: 1 can/jar/tin of stuff\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT')], 'AMT'], ('stuff', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 pkg stuff \n",
      "\n",
      "IN: 1 can, jar, or tin of stuff\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT')], 'AMT'], ('stuff', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 pkg stuff \n",
      "\n",
      "IN: 1 can, jar or tin of stuff\n",
      "PARSED: [[[[[('1.0', 'QTY'), ('can', 'UNIT')], 'AMT'], ('stuff', 'NN')], 'INGRED']]\n",
      "OUT: 1.0 pkg stuff \n",
      "\n",
      "IN: 6dingus 2 cup / 3\n",
      "PARSED: [[[[[('6', 'QTY'), ('ea', 'UNIT')], 'AMT'], [[('2.0', 'QTY'), ('cup', 'UNIT')], 'AMT'], [[('3.0', 'QTY'), ('ea', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 6.0 ea 473.176 ml 3.0 ea \n",
      "\n",
      "IN: 6 2 cup / 3\n",
      "PARSED: [[[[[('6.0', 'QTY'), ('ea', 'UNIT')], 'AMT'], [[('2.0', 'QTY'), ('cup', 'UNIT')], 'AMT'], [[('3.0', 'QTY'), ('ea', 'UNIT')], 'AMT']], 'INGRED']]\n",
      "OUT: 6.0 ea 473.176 ml 3.0 ea \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for i, input in enumerate(TEST_INPUT):\n",
    "    print('IN:', input)\n",
    "    parsed = parse(input)\n",
    "    print('PARSED:', parsed)\n",
    "    print('OUT:', detokenize(parsed),'\\n')\n",
    "    # print('{} -> {}\\n'.format(input, detokenize(parse(input))))\n",
    "    # print('<----------------------------->\\n')\n",
    "    if i == 0:\n",
    "        # break\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 cup / 80 grams mild honey\n",
      "1/4 cup / 80 grams honey\n",
      "[{'unit': 'cup', 'qty': 0.25, 'qualifiers': [], 'per': None, 'plus': False}, {'unit': 'g', 'qty': 80.0, 'qualifiers': [], 'per': None, 'plus': False}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'qtys': [{'unit': 'cup',\n",
       "   'qty': 0.25,\n",
       "   'qualifiers': [],\n",
       "   'per': None,\n",
       "   'plus': False},\n",
       "  {'unit': 'g', 'qty': 80.0, 'qualifiers': [], 'per': None, 'plus': False}],\n",
       " 'names': ['honey'],\n",
       " 'mods': [],\n",
       " 'stripped_words': ['mild']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from parser import amounts\n",
    "\n",
    "amounts('1/4 cup/80 grams mild honey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('red', 'JJ'),\n",
       " (',', ','),\n",
       " ('white', 'JJ'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('blue', 'JJ'),\n",
       " ('corn', 'NN')]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing = 'red, white, or blue corn'\n",
    "nltk.pos_tag(nltk.word_tokenize(ing))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
